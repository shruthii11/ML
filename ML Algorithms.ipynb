{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee1b23b9",
   "metadata": {},
   "source": [
    "## FIND-Salgorithm for finding the most specific hypothesis based on a given set of training data sample and LIST THEN ELIMINATE algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69230bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = pd.read_csv('Prog1&2_FindS_CandidateElimination.csv')\n",
    "def list_then_eliminate(concepts, target):\n",
    "    positive_examples = concepts[target == 'Yes']\n",
    "    specific_hypothesis = positive_examples[0].copy()\n",
    "    for example in positive_examples[1:]:\n",
    "        for i, attribute in enumerate(example):\n",
    "            if attribute != specific_hypothesis[i]:\n",
    "                specific_hypothesis[i] = '?'\n",
    "    return specific_hypothesis\n",
    "def train(concepts, target):\n",
    "    for i, val in enumerate(target):\n",
    "        if val == \"Yes\":\n",
    "            specific_h = concepts[i]\n",
    "            break\n",
    "    for i, h in enumerate(concepts):\n",
    "        if target[i] == \"Yes\":\n",
    "            for x in range(len(specific_h)):\n",
    "                if h[x] == specific_h[x]:\n",
    "                    pass\n",
    "                else:\n",
    "                    specific_h[x] = \"?\"\n",
    "    return specific_h\n",
    "concepts = np.array(data.iloc[:,0:-1])\n",
    "target = np.array(data.iloc[:,-1])\n",
    "print('Specific hypothesis obtained by LIST THEN ELIMINATE algorithm:')\n",
    "print(list_then_eliminate(concepts, target))\n",
    "print('\\nSpecific hypothesis obtained by the original code:')\n",
    "print(train(concepts, target))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b06ace5",
   "metadata": {},
   "source": [
    "\n",
    "## Candidate-Elimination algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbea3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = pd.DataFrame(data=pd.read_csv('Prog1&2_FindS_CandidateElimination.csv'))\n",
    "concepts = np.array(data.iloc[:,0:-1])\n",
    "target = np.array(data.iloc[:,-1])\n",
    "def learn(concepts, target):\n",
    "    specific_h = concepts[0].copy()\n",
    "    general_h = [[\"?\" for i in range(len(specific_h))] for i in range(len(specific_h))]\n",
    "    for i, h in enumerate(concepts):\n",
    "        if target[i] == \"Yes\":\n",
    "            for x in range(len(specific_h)):\n",
    "                if h[x] != specific_h[x]:\n",
    "                    specific_h[x] = '?'\n",
    "                    general_h[x][x] = '?'\n",
    "        if target[i] == \"No\":\n",
    "            for x in range(len(specific_h)):\n",
    "                if h[x] != specific_h[x]:\n",
    "                    general_h[x][x] = specific_h[x]\n",
    "                else:\n",
    "                    general_h[x][x] = '?'\n",
    "    indices = [i for i,val in enumerate(general_h) if val == ['?','?','?','?','?','?']]\n",
    "    for i in indices:\n",
    "        general_h.remove(['?','?','?','?','?','?'])\n",
    "    return specific_h, general_h\n",
    "s_final, g_final = learn(concepts, target)\n",
    "print(\"Final S:\", s_final, sep=\"\\n\")\n",
    "print(\"Final G:\", g_final, sep=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d572dbfa",
   "metadata": {},
   "source": [
    "## Pre processing (Data Cleaning, Integration and Transformation) activity on suitable data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aa25f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data1 = {'A': [1, 2, 2, 3, 4, 5, 5],\n",
    "         'B': [5, 6, 6, 7, 8, 9, 9]}\n",
    "data2 = {'C': [10, 10, 10, 10, 10],\n",
    "         'D': [11, 12, 13, 14, 15]}\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "print(\"Before removing duplicates in dataset 1:\")\n",
    "print(df1)\n",
    "df1.drop_duplicates(inplace=True)\n",
    "print(\"\\nAfter removing duplicates in dataset 1:\")\n",
    "print(df1)\n",
    "print(\"\\nBefore removing single value columns in dataset 2:\")\n",
    "print(df2)\n",
    "cols_to_remove = [col for col in df2.columns if df2[col].nunique() <= 1]\n",
    "df2.drop(cols_to_remove, axis=1, inplace=True)\n",
    "print(\"\\nAfter removing single value columns in dataset 2:\")\n",
    "print(df2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87b18943",
   "metadata": {},
   "source": [
    "\n",
    "## Decision tree based ID3 algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce9c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "data = pd.read_csv(\"Prog4_ID3.csv\")\n",
    "X = data.drop('Play', axis=1)\n",
    "y = data['Play']\n",
    "X = pd.get_dummies(X)\n",
    "y = y.map({'yes': 1, 'no': 0})\n",
    "classifier = DecisionTreeClassifier(criterion='entropy')\n",
    "classifier.fit(X, y)\n",
    "export_graphviz(classifier, out_file='tree.dot', feature_names=X.columns)\n",
    "with open('tree.dot', 'r') as file:\n",
    "    tree_data = file.read()\n",
    "print(tree_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2816f35",
   "metadata": {},
   "source": [
    "\n",
    "## Random forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebfad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "new_sample = [[3, 5, 4, 2]]\n",
    "new_pred = clf.predict(new_sample)\n",
    "print(\"Predicted class of new sample: \", new_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d2e19e9",
   "metadata": {},
   "source": [
    "\n",
    "## naÃ¯ve Bayesian classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbbf86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data should contain all possible outputs values that can be given to any attribute\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "def gaussian_naive_bayes(data, test_data):\n",
    "    X = data.iloc[:, :-1]\n",
    "    y = data.iloc[:, -1]\n",
    "    X = pd.get_dummies(X)\n",
    "    nb = GaussianNB()\n",
    "    nb.fit(X, y)\n",
    "    y_pred_new = nb.predict(pd.get_dummies(test_data.iloc[:, :-1]))\n",
    "    accuracy_new = accuracy_score(test_data.iloc[:, -1], y_pred_new)\n",
    "    print(\"Accuracy on Test data set:\", accuracy_new)\n",
    "\n",
    "data = pd.read_csv(\"Prog6_train_data.csv\")\n",
    "test_data = pd.read_csv(\"Prog6_test_data.csv\")\n",
    "gaussian_naive_bayes(data, test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fbf0e87",
   "metadata": {},
   "source": [
    "\n",
    "## Calculation of accuracy, precision, and recall for data set using naive Bayesian Classifier model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5209fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(newsgroups_train.data)\n",
    "X_test = vectorizer.transform(newsgroups_test.data)\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6ecc985",
   "metadata": {},
   "source": [
    "\n",
    "## Construction of a Bayesian network considering medical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6115463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator, BayesianEstimator\n",
    "data = pd.read_csv('Prog8_Bayesian_network.csv')\n",
    "model = BayesianNetwork()\n",
    "model.add_edges_from([('age', 'heartDisease'), \n",
    "                      ('sex', 'heartDisease'), \n",
    "                      ('cp', 'heartDisease'), \n",
    "                      ('trestbps', 'heartDisease'), \n",
    "                      ('chol', 'heartDisease')])\n",
    "model.fit(data, estimator=MaximumLikelihoodEstimator)\n",
    "age = input(\"Enter age (SeniorCitizen/Teen/Youth/MiddleAged): \")\n",
    "sex = input(\"Enter sex (Male/Female): \")\n",
    "cp = input(\"Enter chest pain type (Typical angina/Atypical angina/Non-anginal pain): \")\n",
    "trestbps = input(\"Enter resting blood pressure (High/Normal/Low): \")\n",
    "chol = input(\"Enter cholesterol level (High/Normal/Low): \")\n",
    "user_data = pd.DataFrame({'age': [age], 'sex': [sex], 'cp': [cp], 'trestbps': [trestbps], 'chol': [chol]})\n",
    "prediction =  model.predict(user_data)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c949688",
   "metadata": {},
   "source": [
    "\n",
    "## EM algorithm to cluster a set of data stored in a .CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4491be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "data = pd.read_csv('Prog9_EM.csv')\n",
    "X = data.values\n",
    "num_clusters = 3\n",
    "gmm = GaussianMixture(n_components=num_clusters)\n",
    "gmm.fit(X)\n",
    "labels = gmm.predict(X)\n",
    "print('Cluster Labels:')\n",
    "print(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6e5245c",
   "metadata": {},
   "source": [
    "\n",
    "##  SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d16c1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.2, random_state=42)\n",
    "\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification report:\\n\", report)\n",
    "\n",
    "clf = SVC(C=100,gamma=0.0001)\n",
    "pca = PCA(n_components = 2)\n",
    "\n",
    "X_train2 = pca.fit_transform(X_train)\n",
    "clf.fit(X_train2, y_train)\n",
    "\n",
    "plot_decision_regions(X_train2, y_train, clf=clf, legend=2)\n",
    "plt.xlabel('mean radius')\n",
    "plt.ylabel('mean texture')\n",
    "plt.title('SVM decision boundary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab0d1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "c347c8f9a7ef94e4c9e03b4513be7835ed18f45b99a2a817fb579f408b867b16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
